{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOqcKS6z1A8eHP/tNPAOnUB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/YouTube_DL/blob/main/Faster_Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0x-K2ViIzMfD"
      },
      "outputs": [],
      "source": [
        "!pip install -U yt-dlp\n",
        "!pip install -U faster_whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**一つの動画を文字起こし**"
      ],
      "metadata": {
        "id": "8ia4y3dYhsAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import re\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "YOUTUBE_ID = \"TOVAc1YCgag\"  # Youtube ID\n",
        "AUDIO_FILE_NAME = f\"{YOUTUBE_ID}.mp3\"\n",
        "\n",
        "# Download audio and metadata from Youtube\n",
        "def dl_yt(yt_url):\n",
        "    # Download audio\n",
        "    subprocess.run(f\"yt-dlp -x --audio-format mp3 -o {AUDIO_FILE_NAME} {yt_url}\", shell=True)\n",
        "    # Get metadata\n",
        "    result = subprocess.run(f\"yt-dlp -j {yt_url}\", shell=True, capture_output=True, text=True)\n",
        "    return result.stdout\n",
        "\n",
        "metadata = dl_yt(f\"https://youtu.be/{YOUTUBE_ID}\")\n",
        "\n",
        "# Extract title from metadata\n",
        "import json\n",
        "metadata_json = json.loads(metadata)\n",
        "title = metadata_json.get(\"title\", YOUTUBE_ID)\n",
        "\n",
        "# Sanitize the title to be used as a filename\n",
        "safe_title = re.sub(r'[\\\\/*?:\"<>|]', \"\", title)\n",
        "\n",
        "TRANSCRIPTION_FILE_NAME = f\"{safe_title}_transcription.txt\"\n",
        "\n",
        "model_size = \"large-v2\"\n",
        "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "segments, info = model.transcribe(AUDIO_FILE_NAME, beam_size=5)\n",
        "\n",
        "# Print detected language\n",
        "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
        "\n",
        "# Write the transcription to a file\n",
        "with open(TRANSCRIPTION_FILE_NAME, \"w\", encoding=\"utf-8\") as file:\n",
        "    for segment in segments:\n",
        "        file.write(f\"{segment.text}\\n\")\n",
        "        print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
        "\n",
        "print(f\"Transcription saved to {TRANSCRIPTION_FILE_NAME}\")\n"
      ],
      "metadata": {
        "id": "z30GBEo099a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**動画ID --> CHHANNEL_URL --> すべての動画をDL**"
      ],
      "metadata": {
        "id": "RjZLrvenH7Ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "VIDEO_ID = \"YaK2pwtavi4\"  # 動画IDをここに設定\n",
        "AUDIO_DIR = \"downloaded_audio\"\n",
        "TRANSCRIPTION_DIR = \"transcriptions\"\n",
        "\n",
        "# ディレクトリ確認・作成\n",
        "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
        "os.makedirs(TRANSCRIPTION_DIR, exist_ok=True)\n",
        "\n",
        "# YouTube動画からチャンネルURLを取得\n",
        "def get_channel_url_from_video(video_id):\n",
        "    result = subprocess.run(f\"yt-dlp -j https://youtu.be/{video_id}\", shell=True, capture_output=True, text=True)\n",
        "    video_data = json.loads(result.stdout)\n",
        "    return video_data[\"channel_url\"]\n",
        "\n",
        "def list_videos(channel_url):\n",
        "    result = subprocess.run(f\"yt-dlp -j --flat-playlist {channel_url}\", shell=True, capture_output=True, text=True)\n",
        "    lines = result.stdout.split('\\n')  # 出力を行に分割\n",
        "    videos = []\n",
        "    for line in lines:\n",
        "        if line:  # 空の行を無視\n",
        "            try:\n",
        "                video = json.loads(line)\n",
        "                videos.append((video['id'], video['title']))\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON decoding error: {e} for line: {line}\")\n",
        "    return videos\n",
        "\n",
        "\n",
        "# メイン処理\n",
        "CHANNEL_URL = get_channel_url_from_video(VIDEO_ID)\n",
        "videos = list_videos(CHANNEL_URL)\n",
        "\n",
        "# 以下、既存のdl_yt, transcribe_and_save 関数と動画処理ループを使用\n",
        "print(CHANNEL_URL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJAcm68QH6ML",
        "outputId": "2ec85e4a-6a60-4464-e6ae-332af99d30b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.youtube.com/channel/UCH9YK4B72yMjRPsVgx-EXxw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W4HMHHML5d0",
        "outputId": "a17f14f2-4d3a-4119-b550-941529282b97"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############\n",
        "# Create file list #\n",
        "##############\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "VIDEO_ID = \"YaK2pwtavi4\"  # Set the video ID\n",
        "BASE_PATH = \"/content/drive/MyDrive/YouTube\"  # Base path\n",
        "\n",
        "def get_channel_info_from_video(video_id):\n",
        "    result = subprocess.run(f\"yt-dlp -j https://youtu.be/{video_id}\", shell=True, capture_output=True, text=True)\n",
        "    video_data = json.loads(result.stdout)\n",
        "    channel_url = video_data[\"channel_url\"]\n",
        "    channel_name = video_data[\"channel\"]\n",
        "    return channel_url, channel_name\n",
        "\n",
        "def create_directories(channel_name):\n",
        "    path = os.path.join(BASE_PATH, channel_name)\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    os.makedirs(os.path.join(path, \"audio\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(path, \"transcriptions\"), exist_ok=True)\n",
        "    return path\n",
        "\n",
        "def list_videos(channel_url):\n",
        "    result = subprocess.run(f\"yt-dlp -j --flat-playlist {channel_url}\", shell=True, capture_output=True, text=True)\n",
        "    lines = result.stdout.strip().split('\\n')\n",
        "    videos = []\n",
        "    for line in lines:\n",
        "        if line:\n",
        "            try:\n",
        "                video_data = json.loads(line)\n",
        "                video_id = video_data['id']\n",
        "                video_title = video_data['title']\n",
        "                video_view_count = video_data.get('view_count', 0)  # Default to 0 if view count is not available\n",
        "                videos.append((video_id, video_title, video_view_count))\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding JSON for line: {line}\\nError: {e}\")\n",
        "    return videos\n",
        "\n",
        "def list_videos_sorted_by_view_count(channel_url):\n",
        "    videos = list_videos(channel_url)\n",
        "    # Sort videos by view count in descending order\n",
        "    sorted_videos = sorted(videos, key=lambda x: x[2], reverse=True)\n",
        "    df = pd.DataFrame(sorted_videos, columns=['ID', 'Title', 'View Count'])\n",
        "    return df\n",
        "\n",
        "# Get channel information\n",
        "CHANNEL_URL, channel_name = get_channel_info_from_video(VIDEO_ID)\n",
        "\n",
        "# Create necessary directories\n",
        "channel_path = create_directories(channel_name)\n",
        "\n",
        "# Sort and list videos\n",
        "videos_df = list_videos_sorted_by_view_count(CHANNEL_URL)\n",
        "\n",
        "# Print results\n",
        "print(f\"Channel Name: {channel_name}\")\n",
        "print(videos_df)\n"
      ],
      "metadata": {
        "id": "j9iEcFV2hoEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# Download mp3 files #\n",
        "##################\n",
        "\n",
        "import re\n",
        "\n",
        "def download_video(video_id, title, base_path):\n",
        "    safe_title = re.sub(r'[\\\\/*?:\"<>|]', \"\", title)  # Remove any characters that are invalid in filenames\n",
        "    audio_file_path = os.path.join(base_path, \"audio\", f\"{safe_title}.mp3\")\n",
        "    subprocess.run(f\"yt-dlp -x --audio-format mp3 -o \\\"{audio_file_path}\\\" https://youtu.be/{video_id}\", shell=True)\n",
        "\n",
        "# Prompt user for starting index\n",
        "start_index = int(input(\"Enter the starting index (0 for beginning): \"))\n",
        "\n",
        "# Download videos starting from the provided index\n",
        "for index, row in videos_df.iterrows():\n",
        "    if index >= start_index:\n",
        "        video_id, title, view_count = row['ID'], row['Title'], row['View Count']\n",
        "        print(f\"Downloading video {index + 1}/{len(videos_df)}: {title}\")\n",
        "        download_video(video_id, title, channel_path)\n",
        "\n",
        "print(\"All videos downloaded.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xSEHzILonbwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################\n",
        "# transcript to text #\n",
        "#################\n",
        "\n",
        "from faster_whisper import WhisperModel\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "def transcribe_and_save(audio_file_path, transcription_file_path, video_title):\n",
        "    model_size = \"large-v2\"\n",
        "    model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "    segments, info = model.transcribe(audio_file_path, beam_size=5)\n",
        "\n",
        "    with open(transcription_file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(f\"title: {video_title}\\n\")\n",
        "        for segment in tqdm(segments, desc=\"Transcribing Audio\"):\n",
        "            file.write(f\"{segment.text}\\n\")\n",
        "\n",
        "def safe_file_name(title):\n",
        "    \"\"\"Create a safe file name by removing invalid characters.\"\"\"\n",
        "    return re.sub(r'[\\\\/*?:\"<>|]', \"\", title)\n",
        "\n",
        "def create_transcription_file_lists(videos_df, channel_path):\n",
        "    audio_files = []\n",
        "    transcription_files = []\n",
        "    titles = []\n",
        "    for index, row in tqdm(videos_df.iterrows(), total=videos_df.shape[0], desc=\"Processing Videos\"):\n",
        "        video_id = row['ID']\n",
        "        title = safe_file_name(row['Title'])\n",
        "        audio_file_path = os.path.join(channel_path, \"audio\", f\"{title}.mp3\")\n",
        "        transcription_file_path = os.path.join(channel_path, \"transcriptions\", f\"{title}.txt\")\n",
        "        audio_files.append(audio_file_path)\n",
        "        transcription_files.append(transcription_file_path)\n",
        "        titles.append(row['Title'])\n",
        "    return audio_files, transcription_files, titles\n",
        "\n",
        "# Generate file lists for transcription\n",
        "audio_files, transcription_files, titles = create_transcription_file_lists(videos_df, channel_path)\n",
        "\n",
        "# Transcribe and save\n",
        "for audio_file, transcription_file, title in zip(audio_files, transcription_files, titles):\n",
        "    print(title)\n",
        "    transcribe_and_save(audio_file, transcription_file, title)\n"
      ],
      "metadata": {
        "id": "zfJDTDhmL5bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "__svfP7YhWyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JenjprKxhW23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cv5EbHLFhW6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from faster_whisper import WhisperModel\n",
        "import os\n",
        "\n",
        "def transcribe_and_save(audio_file_path, transcription_file_path):\n",
        "    model_size = \"large-v2\"\n",
        "    model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "    segments, info = model.transcribe(audio_file_path, beam_size=5)\n",
        "\n",
        "    with open(transcription_file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        for segment in segments:\n",
        "            file.write(f\"{segment.text}\\n\")\n",
        "\n",
        "# 以下の部分をオーディオファイルのリスト処理ループに組み込む\n",
        "transcribe_and_save(audio_file_path, transcription_file_path)\n"
      ],
      "metadata": {
        "id": "nHEGAcrGL96_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}